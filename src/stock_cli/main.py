"""Stock Agent CLI (MVP)

ç‰¹æ€§ (èšç„¦ Agent èƒ½åŠ› / ç±» Gemini CLI ä½“éªŒ):
    - ask: å•è½®é—®ç­”, æ”¯æŒ --model è¦†ç›–, --json ç»“æ„åŒ–è¾“å‡º, --show-thought æ˜¾ç¤ºæ¨ç†é˜¶æ®µ
    - chat: å¤šè½®å¯¹è¯ (é¦–è½®æµå¼è¾“å‡º)

JSON è¾“å‡ºç»“æ„: {"answer","model","latency","reasoning"}
"""

from __future__ import annotations

import asyncio
import logging
import time
import sys
import signal
from typing import Optional, List, Dict, Any
from pathlib import Path

import typer
from rich import print
from rich.panel import Panel
from rich.console import Console
import yaml
from pyfiglet import Figlet
from prompt_toolkit import PromptSession
from prompt_toolkit.history import FileHistory
from prompt_toolkit.auto_suggest import AutoSuggestFromHistory

from .agent.runtime import ensure_kernel, current_model
from .tools.mcp_server_manager import MCPServerManager

app = typer.Typer(add_completion=False, help="Stock Agent CLI - AIé©±åŠ¨çš„è‚¡ç¥¨åˆ†æå·¥å…·")
console = Console()

__version__ = "1.0.0"


@app.command()
def version():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    console.print(f"Stock Agent CLI v{__version__}")
    console.print("AI-Powered Stock Analysis Tool powered by ReAct Architecture")


@app.callback(invoke_without_command=True)
def main_callback(
    ctx: typer.Context,
    version: bool = typer.Option(False, "--version", "-V", help="æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"),
):
    """Stock Agent CLI - AIé©±åŠ¨çš„è‚¡ç¥¨åˆ†æå·¥å…·"""
    if version:
        console.print(f"Stock Agent CLI v{__version__}")
        console.print("AI-Powered Stock Analysis Tool powered by ReAct Architecture")
        raise typer.Exit()

    if ctx.invoked_subcommand is None:
        # é»˜è®¤è¿›å…¥å¯¹è¯æ¨¡å¼
        if not _check_llm_config():
            console.print("[red]LLMé…ç½®ä¸å®Œæ•´ï¼Œè¯·é…ç½® config/settings.yaml[/red]")
            raise typer.Exit(1)

        _setup_logging("ERROR")
        asyncio.run(
            _interactive(None, None, False, True, False, False, False)
        )  # é»˜è®¤å¯ç”¨ verbose


# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨å½“å‰è¿è¡Œçš„ä»»åŠ¡
_current_task: Optional[asyncio.Task] = None
_interrupt_requested: bool = False

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨æŒä¹…çš„å¯¹è¯ä¸Šä¸‹æ–‡
_persistent_context: Dict[str, Any] = {}

# åˆ›å»ºPromptSessionå®ä¾‹ä»¥æ”¯æŒä¸­æ–‡è¾“å…¥
session = PromptSession(
    history=FileHistory("data/history.txt"),
    auto_suggest=AutoSuggestFromHistory(),
)


def _setup_logging(level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—é…ç½®ï¼Œåªè¾“å‡ºåˆ°æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°"""
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = Path("data/logs")
    log_dir.mkdir(parents=True, exist_ok=True)

    # å®Œå…¨æ¸…é™¤ç°æœ‰çš„æ—¥å¿—å¤„ç†å™¨
    logging.getLogger().handlers.clear()

    # é…ç½®æ ¹æ—¥å¿—åªè¾“å‡ºåˆ°æ–‡ä»¶
    logging.basicConfig(
        level=logging.ERROR,  # æé«˜é˜ˆå€¼ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
        datefmt="%m/%d/%y %H:%M:%S",
        handlers=[
            logging.FileHandler("data/logs/agent.log", encoding="utf-8"),
        ],
        force=True,  # å¼ºåˆ¶é‡æ–°é…ç½®
    )

    # ç¦ç”¨æ‰€æœ‰å¯èƒ½äº§ç”Ÿæ§åˆ¶å°è¾“å‡ºçš„æ—¥å¿—
    noisy_loggers = [
        "posthog",
        "httpx",
        "httpcore",
        "openai",
        "mcp",
        "anyio",
        "asyncio",
        "src.tools.mcp_server_manager",
        "mcp.server.lowlevel.server",
        "__main__",
        "src.tools.mcp_server.stock_core_server",
        "src.tools.mcp_server.stock_news_server",
        "src.tools.mcp_server.time_server",
    ]

    for logger_name in noisy_loggers:
        logger = logging.getLogger(logger_name)
        logger.setLevel(logging.CRITICAL)  # åªå…è®¸ä¸¥é‡é”™è¯¯
        logger.propagate = False
        # ç§»é™¤æ‰€æœ‰å¤„ç†å™¨
        logger.handlers.clear()


def _check_llm_config() -> bool:
    """æ£€æŸ¥LLMé…ç½®æ˜¯å¦å®Œæ•´"""
    project_root = Path(__file__).resolve().parent.parent.parent
    settings_path = project_root / "config" / "settings.yaml"

    print(f"DEBUG: é…ç½®æ–‡ä»¶è·¯å¾„: {settings_path}")
    print(f"DEBUG: æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {settings_path.exists()}")

    if not settings_path.exists():
        return False

    try:
        with open(settings_path, "r", encoding="utf-8") as f:
            settings = yaml.safe_load(f) or {}

        llm_config = settings.get("llm", {})

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æœ‰æ•ˆçš„æä¾›å•†é…ç½®
        valid_providers = [
            "openai",
            "deepseek",
            "ollama",
            "gemini",
            "anthropic",
            "azure",
            "custom",
        ]
        for provider in valid_providers:
            if provider in llm_config:
                config = llm_config[provider]
                api_key = config.get("api_key")
                base_url = config.get("base_url")
                model = config.get("model")

                # æ£€æŸ¥é…ç½®æ˜¯å¦å®Œæ•´
                if not api_key or not base_url or not model:
                    continue

                # å¦‚æœæ˜¯æœ¬åœ°æœåŠ¡ï¼ˆollamaï¼‰ï¼Œapi_keyå¯ä»¥æ˜¯"ollama"
                if (
                    "localhost" in base_url
                    or "127.0.0.1" in base_url
                    or "ollama" in base_url.lower()
                ):
                    return True

                return bool(api_key and base_url and model)

        return False
    except Exception:
        return False


def _print_banner(model: str, mode: str):
    # ä»…åœ¨ verbose æ¨¡å¼è°ƒç”¨
    line = f"model={model} mode={mode}"
    console.print(f"[dim]{line}[/dim]")


def _format_reasoning(lines: List[str]) -> List[str]:
    out: List[str] = []
    for ln in lines:
        if ln.startswith("[Agent]"):
            out.append(f"[cyan]> {ln.replace('[Agent]', '').strip()}[/cyan]")
        elif ln.startswith("[ReAct]"):
            core = ln.replace("[ReAct]", "").strip()
            out.append(f"[dim]â€¢ {core}[/dim]")
    return out


def _show_logo():
    """æ˜¾ç¤ºä¸“ä¸šé£æ ¼çš„logo"""
    f = Figlet(font="slant", width=120)
    logo_text = f.renderText("Stock Agent CLI")
    console.print(f"[bold blue]{logo_text}[/bold blue]")
    console.print(
        "[green]AI-Powered Stock Analysis Tool powered by ReAct Architecture[/green]\n"
    )


def _show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    help_text = f"""
[bold blue]Stock Agent CLI v{__version__} - å¸®åŠ©[/bold blue]

[yellow]åŸºæœ¬ç”¨æ³•:[/yellow]
  ç›´æ¥è¾“å…¥é—®é¢˜ä¸AIå¯¹è¯ï¼Œæ‰€æœ‰æ¨¡å¼éƒ½ä¼šæ˜¾ç¤ºAIçš„æ€è€ƒè¿‡ç¨‹

[yellow]ä¸­æ–­åŠŸèƒ½:[/yellow]
  åœ¨ä»»ä½•æ¨¡å¼ä¸‹ï¼Œå½“ AI æ­£åœ¨æ€è€ƒæˆ–ç”Ÿæˆç­”æ¡ˆæ—¶ï¼š
  â€¢ æŒ‰ Ctrl+C å¯ä»¥ä¸­æ–­å½“å‰ä»»åŠ¡
  â€¢ ä¸­æ–­åå¯ä»¥ç«‹å³è¾“å…¥æ–°çš„é—®é¢˜
  
[yellow]ç‰¹æ®Šå‘½ä»¤:[/yellow]
  /help, /h      - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  /tools         - åˆ—å‡ºå¯ç”¨å·¥å…·
  /status        - æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€  
  /clear         - æ¸…å±
  /version       - æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
  /quit, /exit   - é€€å‡ºç¨‹åº

[yellow]ç¤ºä¾‹é—®é¢˜:[/yellow]
  åˆ†æä¸€ä¸‹é˜¿é‡Œå·´å·´çš„è‚¡ä»·èµ°åŠ¿
  å¸®æˆ‘æŸ¥æ‰¾æœ€è¿‘çš„è‚¡å¸‚æ–°é—»
  æ¯”è¾ƒä¸€ä¸‹è…¾è®¯å’Œé˜¿é‡Œå·´å·´çš„è´¢åŠ¡æ•°æ®

[yellow]å‘½ä»¤è¡Œé€‰é¡¹:[/yellow]
  --help         - æ˜¾ç¤ºå‘½ä»¤å¸®åŠ©
  --version, -V  - æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
  --debug, -d    - æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
  --no-color     - ç¦ç”¨å½©è‰²è¾“å‡º
"""
    console.print(help_text.strip())


def _show_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    try:
        model = current_model()
        status = "Active" if model else "Check configuration"
        model_name = model or "Check configuration"

        status_text = f"""
Status: {status}
Model: {model_name}
Services: Running
"""
        console.print(status_text.strip())
    except Exception:
        console.print("Status: Unable to determine")


async def _show_tools():
    """æ˜¾ç¤ºå½“å‰å¯ç”¨çš„MCPå·¥å…·"""
    try:
        mgr = await MCPServerManager.get_instance()
        tools = await mgr.list_tools()
    except Exception as e:  # noqa: BLE001
        console.print(f"[red]Failed to fetch tools: {e}")
        return
    if not tools:
        console.print("[yellow]No tools available[/yellow]")
        return
    rows = [f"[bold]{t.name}[/bold]: {getattr(t, 'description', '')}" for t in tools]
    console.print(
        Panel("\n".join(rows), title=f"Tools ({len(rows)})", border_style="cyan")
    )


async def _cleanup_mcp():
    """æ¸…ç†MCPæœåŠ¡å™¨ç®¡ç†å™¨"""
    try:
        mgr = await MCPServerManager.get_instance()
        await mgr.cleanup()
    except Exception:  # noqa: BLE001
        # å¿½ç•¥æ¸…ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ï¼Œé¿å…å¹²æ‰°ä¸»ç¨‹åºé€€å‡º
        pass


def _signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å‡½æ•°ï¼Œç”¨äºå¤„ç† Ctrl+C"""
    global _interrupt_requested, _current_task

    if _current_task and not _current_task.done():
        console.print("\n[yellow]ğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢å½“å‰ä»»åŠ¡...[/yellow]")
        _interrupt_requested = True
        _current_task.cancel()
    else:
        # å¦‚æœæ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ï¼Œç›´æ¥é€€å‡º
        console.print("\n[red]Exiting...[/red]")
        sys.exit(0)


def _setup_signal_handlers():
    """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
    signal.signal(signal.SIGINT, _signal_handler)  # Ctrl+C


async def _run_agent_with_interrupt(
    question: str,
    *,
    stream: bool = True,
    capture_steps: bool = False,
    minimal: bool = False,
    enable_interrupt: bool = False,
    use_persistent_context: bool = False,
) -> dict:
    """è¿è¡Œå•ä¸ª Agent ä»»åŠ¡å¹¶è¿”å›ç»“æœ/æ¨ç†æ‘˜è¦ï¼Œæ”¯æŒè¿è¡Œæ—¶ä¸­æ–­ã€‚"""
    global _current_task, _interrupt_requested, _persistent_context

    # é‡ç½®ä¸­æ–­æ ‡å¿—
    _interrupt_requested = False

    kernel = await ensure_kernel()
    start_t = time.time()
    progress_lines: List[str] = []

    # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
    async def on_progress(chunk: str):
        # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°ä¸­æ–­è¯·æ±‚
        if _interrupt_requested:
            raise asyncio.CancelledError("ç”¨æˆ·ä¸­æ–­")

        if chunk.startswith("[Stream]"):
            text = chunk.replace("[Stream]", "")
            # ä½¿ç”¨printç›´æ¥è¾“å‡ºï¼Œé¿å…Richçš„æ½œåœ¨æˆªæ–­é—®é¢˜
            print(text, end="", flush=True)
        elif not minimal and chunk.startswith("[StreamThought]"):
            text = chunk.replace("[StreamThought]", "")
            console.print(f"[dim]{text}[/dim]", end="", highlight=False)
        elif not minimal and chunk.startswith("[StreamAction]"):
            text = chunk.replace("[StreamAction]", "")
            console.print(f"[dim]{text}[/dim]", end="")
        elif not minimal and chunk.startswith("[ThoughtHeader]"):
            console.print("\n[dim]ğŸ’­ thinking: [/dim]", end="")
        elif not minimal and chunk.startswith("[ActionHeader]"):
            console.print("\n[dim]âš¡ action: [/dim]", end="")
        elif not minimal and chunk.startswith("[FinalAnswerHeader]"):
            # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆæ ‡é¢˜å’Œä¸Šæ–¹æ¨ªçº¿
            title = "âœ… æœ€ç»ˆç­”æ¡ˆ"
            console.print(f"\n[bold green]{title}[/bold green]")
            console.print("â”€" * 50)
        elif not minimal and chunk.startswith("[StreamFinalAnswer]"):
            text = chunk.replace("[StreamFinalAnswer]", "")
            # æœ€ç»ˆç­”æ¡ˆä½¿ç”¨æ­£å¸¸é¢œè‰²æ˜¾ç¤ºï¼Œä¸ç”¨dim
            print(text, end="", flush=True)
        elif not minimal and chunk.startswith("[FinalAnswerEnd]"):
            # æœ€ç»ˆç­”æ¡ˆç»“æŸï¼Œæ˜¾ç¤ºä¸‹æ–¹æ¨ªçº¿
            console.print(f"\n{'â”€' * 50}")
        elif not minimal and chunk.startswith("[StreamThought]"):
            text = chunk.replace("[StreamThought]", "")
            console.print(f"[dim]{text}[/dim]", end="")
        elif not minimal and chunk.startswith("[Thought]"):
            console.print(
                f"\n[dim]ğŸ’­ thinking: {chunk.replace('[Thought]', '').strip()}[/dim]"
            )
        elif not minimal and chunk.startswith("[Action]"):
            console.print(
                f"\n[dim]âš¡ action: {chunk.replace('[Action]', '').strip()}[/dim]"
            )
        # è¿‡æ»¤æ‰åŸå§‹çš„ReActå…³é”®è¯
        elif not minimal and chunk.strip() in ["Action", "Thought", "Final Answer"]:
            pass  # å¿½ç•¥è¿™äº›åŸå§‹å…³é”®è¯
        if capture_steps and (
            chunk.startswith("[Thought]") or chunk.startswith("[Action]")
        ):
            progress_lines.append(chunk)

    from .core.types import Task

    # æ ¹æ®æ¨¡å¼å†³å®šä½¿ç”¨ä»€ä¹ˆä¸Šä¸‹æ–‡
    if use_persistent_context:
        # chat æ¨¡å¼ï¼šä½¿ç”¨æŒä¹…ä¸Šä¸‹æ–‡
        if "conversation_history" not in _persistent_context:
            _persistent_context["conversation_history"] = []

        # å°†å½“å‰é—®é¢˜æ·»åŠ åˆ°å¯¹è¯å†å²
        _persistent_context["conversation_history"].append(
            {"role": "user", "content": question}
        )

        task = Task(description=question, context=_persistent_context)
    else:
        # ask æ¨¡å¼ï¼šä½¿ç”¨ç©ºä¸Šä¸‹æ–‡
        task = Task(description=question, context={})

    # åˆ›å»º agent æ‰§è¡Œä»»åŠ¡
    _current_task = asyncio.create_task(
        kernel.execute_task(task, progress_cb=on_progress, stream=stream)
    )

    try:
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        answer = await _current_task

        # å¦‚æœä½¿ç”¨æŒä¹…ä¸Šä¸‹æ–‡ï¼Œä¿å­˜AIçš„å›ç­”åˆ°å¯¹è¯å†å²
        if use_persistent_context and answer:
            _persistent_context["conversation_history"].append(
                {"role": "assistant", "content": answer}
            )

            # é™åˆ¶å¯¹è¯å†å²é•¿åº¦ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
            max_history_pairs = 8  # ä¿ç•™æœ€è¿‘8è½®å¯¹è¯ï¼ˆ16æ¡æ¶ˆæ¯ï¼‰
            if len(_persistent_context["conversation_history"]) > max_history_pairs * 2:
                # ä¿ç•™æœ€æ–°çš„å¯¹è¯ï¼Œåˆ é™¤æœ€æ—§çš„
                _persistent_context["conversation_history"] = _persistent_context[
                    "conversation_history"
                ][-(max_history_pairs * 2) :]

    except asyncio.CancelledError:
        if _interrupt_requested:
            console.print("\n[yellow]ğŸ›‘ ä»»åŠ¡å·²è¢«ç”¨æˆ·ä¸­æ–­[/yellow]")
        else:
            console.print("\n[yellow]ä»»åŠ¡å·²è¢«åœæ­¢[/yellow]")
        raise
    finally:
        _current_task = None
        _interrupt_requested = False

    latency = round(time.time() - start_t, 3)
    reasoning_fmt = _format_reasoning(progress_lines)
    token_usage = task.context.get("token_usage") or {}

    return {
        "answer": answer,
        "model": current_model(),
        "latency": latency,
        "reasoning": reasoning_fmt,
        "_raw_reasoning": progress_lines,
        "tokens": token_usage,
    }


async def _interactive(
    model: Optional[str] = None,
    once: Optional[str] = None,
    quiet: bool = False,
    verbose: bool = False,
    debug: bool = False,
    human_approval: bool = False,
    confirm: bool = False,
    output_format: str = "text",
    timeout: int = 30,
):
    """äº¤äº’å¼ CLI ä¸»å¾ªç¯"""
    # è®¾ç½®ä¿¡å·å¤„ç†å™¨
    _setup_signal_handlers()

    # ç¡®ä¿ Agent kernel å¯ç”¨ï¼Œå¯ç”¨Human-in-the-Loopï¼ˆå¦‚æœéœ€è¦ï¼‰
    try:
        await ensure_kernel(
            enable_human_loop=human_approval,
            console=console,
            require_final_approval=confirm,
        )
    except Exception:
        console.print("[red]åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡å¤±è´¥[/red]")
        raise typer.Exit(1)

    active_model = current_model() or "unknown"
    if once:
        if verbose:
            _print_banner(active_model, mode="once")
        try:
            res = await _run_agent_with_interrupt(
                once,
                stream=not quiet,
                capture_steps=debug,
                minimal=quiet or (not verbose and not debug),
            )
        except asyncio.CancelledError:
            # ä»»åŠ¡è¢«å–æ¶ˆ
            console.print("[yellow]ä»»åŠ¡å·²è¢«åœæ­¢[/yellow]")
            return
        except Exception as e:  # noqa: BLE001
            console.print(f"[red]Execution failed: {e}")
            return
        # æœ€ç»ˆç­”æ¡ˆå·²ç»é€šè¿‡XMLçŠ¶æ€æœºæµå¼è¾“å‡ºï¼Œæ— éœ€é¢å¤–å¤„ç†

        # æ¨ç†è¿‡ç¨‹å·²ç»å®æ—¶æ˜¾ç¤ºï¼Œä¸å†é‡å¤æ˜¾ç¤º
        return

    # è¿›å…¥äº¤äº’å¾ªç¯
    if verbose:
        _print_banner(active_model, mode="chat")

    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯å’Œlogo
    console.clear()
    _show_logo()
    console.print("[bold green]Welcome to Stock Agent CLI![/bold green]")
    console.print("[dim]Type /help for available commands, /quit to exit[/dim]\n")

    try:
        while True:
            try:
                user_input = await session.prompt_async(
                    "> ",
                    enable_history_search=True,
                )
            except (EOFError, KeyboardInterrupt):
                console.print("\n[red]Exiting...[/red]")
                break
            if not user_input.strip():
                continue

            # å¤„ç†ç‰¹æ®Šå‘½ä»¤ - æ ‡å‡†åŒ–å‘½ä»¤æ ¼å¼
            cmd = user_input.strip().lower()
            if cmd in {"/quit", "/exit"}:
                console.print("[dim]Goodbye![/dim]")
                break
            elif cmd == "/tools":
                await _show_tools()
                continue
            elif cmd == "/status":
                _show_status()
                continue
            elif cmd in {"/help", "/h"}:
                _show_help()
                continue
            elif cmd == "/clear":
                console.clear()
                _show_logo()
                console.print("[bold green]Welcome to Stock Agent CLI![/bold green]")
                console.print(
                    "[dim]Type /help for available commands, /quit to exit[/dim]\n"
                )
                continue
            elif cmd == "/version":
                console.print(f"Stock Agent CLI v{__version__}")
                continue

            console.print(Panel(user_input, title="Question", border_style="cyan"))
            console.print("[dim]ğŸ’¡ æç¤º: æŒ‰ Ctrl+C å¯ä»¥ä¸­æ–­å½“å‰ä»»åŠ¡[/dim]")
            try:
                res = await _run_agent_with_interrupt(
                    user_input,
                    stream=not quiet,
                    capture_steps=debug,
                    minimal=quiet or (not verbose and not debug),
                    enable_interrupt=True,  # åœ¨ chat æ¨¡å¼ä¸‹å¯ç”¨ä¸­æ–­
                    use_persistent_context=True,  # åœ¨chatæ¨¡å¼ä¸‹ä½¿ç”¨æŒä¹…ä¸Šä¸‹æ–‡
                )
            except asyncio.CancelledError:
                # ä»»åŠ¡è¢«å–æ¶ˆï¼Œå·²ç»åœ¨_run_agent_with_interruptä¸­å¤„ç†äº†
                continue
            except Exception as e:  # noqa: BLE001
                console.print(f"[red]Execution failed: {e}")
                continue
            # æœ€ç»ˆç­”æ¡ˆå·²ç»é€šè¿‡XMLçŠ¶æ€æœºæµå¼è¾“å‡ºï¼Œæ— éœ€é¢å¤–å¤„ç†

            # æ¨ç†è¿‡ç¨‹å·²ç»å®æ—¶æ˜¾ç¤ºï¼Œä¸å†é‡å¤æ˜¾ç¤º
    finally:
        # æ¸…ç†MCPèµ„æº
        await _cleanup_mcp()


@app.command()
def ask(
    question: str,
    model: Optional[str] = typer.Option(None, "--model", "-m", help="è¦†ç›–é»˜è®¤æ¨¡å‹"),
    config: Optional[str] = typer.Option(
        None, "--config", "-c", help="æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„"
    ),
    output: str = typer.Option(
        "text", "--output", "-o", help="è¾“å‡ºæ ¼å¼: text|json|yaml"
    ),
    debug: bool = typer.Option(False, "--debug", "-d", help="æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯å’Œæ¨ç†è¿‡ç¨‹"),
    no_color: bool = typer.Option(False, "--no-color", help="ç¦ç”¨å½©è‰²è¾“å‡º"),
    timeout: int = typer.Option(30, "--timeout", "-t", help="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)"),
    human_approval: bool = typer.Option(
        False, "--human-approval", help="å¯ç”¨äººå·¥å®¡æ‰¹æ¨¡å¼"
    ),
    confirm: bool = typer.Option(False, "--confirm", "-y", help="æœ€ç»ˆç­”æ¡ˆéœ€è¦äººå·¥ç¡®è®¤"),
) -> None:
    """å•è½®é—®ç­”æ¨¡å¼ - å‘AIæå‡ºé—®é¢˜å¹¶è·å¾—ç­”æ¡ˆ"""
    # è®¾ç½®ä¿¡å·å¤„ç†å™¨
    _setup_signal_handlers()

    _setup_logging("DEBUG" if debug else "ERROR")

    # æ£€æŸ¥å¹¶è®¾ç½®LLMé…ç½®
    config_file = config or "config/settings.yaml"
    if not _check_llm_config():
        console.print("[red]LLMé…ç½®ä¸å®Œæ•´ï¼Œè¯·é…ç½® config/settings.yaml[/red]")
        raise typer.Exit(1)

    # å¤„ç†è¾“å‡ºæ ¼å¼
    if output not in ["text", "json", "yaml"]:
        console.print("[red]æ— æ•ˆçš„è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒ: text, json, yaml[/red]")
        raise typer.Exit(1)

    # ç¦ç”¨é¢œè‰²è¾“å‡º
    if no_color:
        console.color_system = None

    asyncio.run(
        _interactive(
            model,
            question,
            False,
            True,
            debug,
            human_approval,
            confirm,  # quiet=False, verbose=True
            output_format=output,
            timeout=timeout,
        )
    )


@app.command()
def chat(
    model: str = typer.Option("qwen2.5:7b", "--model", "-m", help="ä½¿ç”¨çš„æ¨¡å‹åç§°"),
    minimal: bool = typer.Option(False, "--minimal", help="æœ€å°åŒ–è¾“å‡º"),
):
    """è¿›å…¥äº¤äº’å¼èŠå¤©æ¨¡å¼ï¼ˆå…·æœ‰è®°å¿†åŠŸèƒ½ï¼‰"""
    # è®¾ç½®ä¿¡å·å¤„ç†å™¨
    _setup_signal_handlers()
    _setup_logging("ERROR")

    # æ£€æŸ¥å¹¶è®¾ç½®LLMé…ç½®
    if not _check_llm_config():
        console.print("[red]LLMé…ç½®ä¸å®Œæ•´ï¼Œè¯·é…ç½® config/settings.yaml[/red]")
        raise typer.Exit(1)

    asyncio.run(
        _interactive(
            model=model,
            once=None,
            quiet=minimal,  # minimalæ¨¡å¼å¯¹åº”quiet
            verbose=not minimal,  # éminimalæ—¶verbose
            debug=False,
            human_approval=False,
            confirm=False,
            output_format="text",
            timeout=30,
        )
    )


@app.command()
def tools() -> None:
    """åˆ—å‡ºå¯ç”¨å·¥å…·"""
    _setup_logging("ERROR")
    asyncio.run(_show_tools())


@app.callback(invoke_without_command=True)
def main(ctx: typer.Context):
    """é»˜è®¤è¿›å…¥å¯¹è¯æ¨¡å¼"""
    if ctx.invoked_subcommand is None:
        # æ£€æŸ¥å¹¶è®¾ç½®LLMé…ç½®
        if not _check_llm_config():
            console.print("[red]LLMé…ç½®ä¸å®Œæ•´ï¼Œè¯·é…ç½® config/settings.yaml[/red]")
            raise typer.Exit(1)

        _setup_logging("ERROR")
        asyncio.run(_interactive())


def main():
    """Entry point for stock-cli command."""
    app()


if __name__ == "__main__":  # pragma: no cover
    app()
